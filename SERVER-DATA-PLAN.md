# üóÑÔ∏è –ü–õ–ê–ù –•–†–ê–ù–ï–ù–ò–Ø –î–ê–ù–ù–´–• –ù–ê –°–ï–†–í–ï–†–ï

> **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–ª—è PSY-TESTS**

## üéØ –¶–µ–ª–∏ —Å–∏—Å—Ç–µ–º—ã —Ö—Ä–∞–Ω–µ–Ω–∏—è

### –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏:
1. **–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ** –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–æ–≤
2. **–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞** –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
3. **–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö** –º–µ–∂–¥—É —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
4. **–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ** –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤
5. **–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ** –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏—è

### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
- –ì—Ä—É–ø–ø–æ–≤–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (–ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É, –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏, —Ä–µ–≥–∏–æ–Ω—É)
- A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–µ—Ä—Å–∏–π —Ç–µ—Å—Ç–æ–≤
- –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ Big Data

## üóÉÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

### PostgreSQL Schema

```sql
-- ================================
-- –û–°–ù–û–í–ù–´–ï –¢–ê–ë–õ–ò–¶–´
-- ================================

-- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,
    age INTEGER,
    gender VARCHAR(20) CHECK (gender IN ('male', 'female', 'other')),
    occupation VARCHAR(255),
    location VARCHAR(255),
    timezone VARCHAR(50),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_active_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    is_active BOOLEAN DEFAULT true
);

-- –ö–∞—Ç–∞–ª–æ–≥ —Ç–µ—Å—Ç–æ–≤
CREATE TABLE tests (
    id VARCHAR(50) PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    category VARCHAR(100),
    version VARCHAR(10) DEFAULT '1.0.0',
    estimated_time_minutes INTEGER,
    max_questions INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    is_active BOOLEAN DEFAULT true
);

-- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤ (–≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)
CREATE TABLE test_configs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    test_id VARCHAR(50) REFERENCES tests(id),
    version VARCHAR(10) NOT NULL,
    config_data JSONB NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    is_active BOOLEAN DEFAULT true,
    UNIQUE(test_id, version)
);

-- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤
CREATE TABLE test_results (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    test_id VARCHAR(50) REFERENCES tests(id),
    test_version VARCHAR(10),
    
    -- –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    raw_score INTEGER NOT NULL,
    final_score INTEGER NOT NULL,
    level VARCHAR(50) NOT NULL,
    
    -- –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
    age_multiplier DECIMAL(3,2),
    gender_multiplier DECIMAL(3,2),
    
    -- –í—Ä–µ–º—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è  
    started_at TIMESTAMP WITH TIME ZONE NOT NULL,
    completed_at TIMESTAMP WITH TIME ZONE NOT NULL,
    duration_seconds INTEGER GENERATED ALWAYS AS 
        (EXTRACT(EPOCH FROM (completed_at - started_at))::INTEGER) STORED,
    
    -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    user_agent TEXT,
    ip_address INET,
    device_type VARCHAR(20), -- 'mobile', 'tablet', 'desktop'
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã
CREATE TABLE question_answers (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    result_id UUID REFERENCES test_results(id) ON DELETE CASCADE,
    question_id VARCHAR(100) NOT NULL,
    question_text TEXT NOT NULL,
    question_type VARCHAR(20) NOT NULL, -- 'single', 'multiple', 'scale'
    
    -- –û—Ç–≤–µ—Ç—ã (–≥–∏–±–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞)
    answer_value JSONB NOT NULL, -- —Å–∞–º –æ—Ç–≤–µ—Ç
    answer_score INTEGER, -- –±–∞–ª–ª—ã –∑–∞ –æ—Ç–≤–µ—Ç
    answer_weight DECIMAL(4,2), -- –≤–µ—Å –æ—Ç–≤–µ—Ç–∞
    
    -- –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
    question_order INTEGER, -- –ø–æ—Ä—è–¥–æ–∫ –≤–æ–ø—Ä–æ—Å–∞ –≤ —Ç–µ—Å—Ç–µ
    time_to_answer_seconds INTEGER, -- –≤—Ä–µ–º—è –Ω–∞ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- –°–µ—Å—Å–∏–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è (–¥–ª—è –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤)
CREATE TABLE test_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    test_id VARCHAR(50) REFERENCES tests(id),
    
    -- –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏
    current_question_index INTEGER DEFAULT 0,
    questions_flow JSONB NOT NULL,
    answered_questions JSONB NOT NULL,
    
    started_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_activity_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    expires_at TIMESTAMP WITH TIME ZONE DEFAULT (NOW() + INTERVAL '7 days'),
    
    is_completed BOOLEAN DEFAULT false
);

-- ================================
-- –ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ï –¢–ê–ë–õ–ò–¶–´  
-- ================================

-- –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
CREATE TABLE daily_stats (
    date DATE PRIMARY KEY,
    test_id VARCHAR(50) REFERENCES tests(id),
    
    -- –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_completions INTEGER DEFAULT 0,
    total_starts INTEGER DEFAULT 0,
    completion_rate DECIMAL(5,2), -- %
    
    -- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —É—Ä–æ–≤–Ω—è–º
    level_minimal_count INTEGER DEFAULT 0,
    level_mild_count INTEGER DEFAULT 0, 
    level_moderate_count INTEGER DEFAULT 0,
    level_high_count INTEGER DEFAULT 0,
    level_critical_count INTEGER DEFAULT 0,
    
    -- –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
    avg_score DECIMAL(8,2),
    avg_duration_minutes DECIMAL(8,2),
    avg_questions_answered DECIMAL(8,2),
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    UNIQUE(date, test_id)
);

-- –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
CREATE TABLE demographic_stats (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    period_start DATE NOT NULL,
    period_end DATE NOT NULL,
    test_id VARCHAR(50) REFERENCES tests(id),
    
    -- –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ —Å—Ä–µ–∑—ã
    age_group VARCHAR(10), -- '18-25', '26-35', etc
    gender VARCHAR(20),
    occupation VARCHAR(255),
    
    -- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
    sample_size INTEGER,
    avg_score DECIMAL(8,2),
    std_deviation DECIMAL(8,2),
    completion_rate DECIMAL(5,2),
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
CREATE TABLE correlations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    test_id VARCHAR(50) REFERENCES tests(id),
    analysis_date DATE NOT NULL,
    
    -- –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É —Ñ–∞–∫—Ç–æ—Ä–∞–º–∏
    age_score_correlation DECIMAL(4,3),
    gender_score_correlation DECIMAL(4,3),
    duration_score_correlation DECIMAL(4,3),
    
    -- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
    sample_size INTEGER,
    confidence_level DECIMAL(4,3),
    
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

### –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```sql
-- –û—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
CREATE INDEX idx_test_results_user_test ON test_results(user_id, test_id);
CREATE INDEX idx_test_results_completed_at ON test_results(completed_at);
CREATE INDEX idx_test_results_level ON test_results(level);
CREATE INDEX idx_test_results_test_completed ON test_results(test_id, completed_at);

-- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
CREATE INDEX idx_question_answers_result_order ON question_answers(result_id, question_order);
CREATE INDEX idx_daily_stats_date_test ON daily_stats(date, test_id);

-- –°–æ—Å—Ç–∞–≤–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤  
CREATE INDEX idx_results_demographics ON test_results(test_id, completed_at) 
    INCLUDE (final_score, level);
CREATE INDEX idx_users_demographics ON users(age, gender, occupation) 
    WHERE is_active = true;

-- GIN –∏–Ω–¥–µ–∫—Å –¥–ª—è JSONB –ø–æ–∏—Å–∫–∞
CREATE INDEX idx_question_answers_value_gin ON question_answers USING GIN (answer_value);
CREATE INDEX idx_test_sessions_flow_gin ON test_sessions USING GIN (questions_flow);
```

## üîå API Endpoints

### REST API –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞

```typescript
// ================================
// –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ò
// ================================

// –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è/–≤—Ö–æ–¥
POST /api/users/register
{
  "name": "string",
  "email": "string", 
  "age": number,
  "gender": "male|female|other",
  "occupation": "string",
  "location": "string"
}

GET /api/users/me
// –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

PUT /api/users/me
// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

// ================================
// –¢–ï–°–¢–´
// ================================

GET /api/tests
// –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤

GET /api/tests/:testId/config
// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–∞ (–≤–æ–ø—Ä–æ—Å—ã, –ª–æ–≥–∏–∫–∞)

// ================================  
// –ü–†–û–•–û–ñ–î–ï–ù–ò–ï –¢–ï–°–¢–û–í
// ================================

POST /api/tests/:testId/sessions
// –ù–∞—á–∞—Ç—å –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é —Ç–µ—Å—Ç–∞

GET /api/tests/:testId/sessions/:sessionId
// –ü–æ–ª—É—á–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏

PUT /api/tests/:testId/sessions/:sessionId
// –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å
{
  "currentQuestionIndex": number,
  "questionsFlow": Question[],
  "answeredQuestions": Record<string, Answer>
}

POST /api/tests/:testId/sessions/:sessionId/complete
// –ó–∞–≤–µ—Ä—à–∏—Ç—å —Ç–µ—Å—Ç –∏ –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
{
  "answeredQuestions": Record<string, Answer>,
  "completedAt": "ISO_DATE",
  "deviceInfo": {...}
}

// ================================
// –†–ï–ó–£–õ–¨–¢–ê–¢–´  
// ================================

GET /api/users/me/results
// –ò—Å—Ç–æ—Ä–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

GET /api/users/me/results/:resultId
// –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –¥–µ—Ç–∞–ª—è–º–∏

POST /api/results/:resultId/feedback
// –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –æ –∫–∞—á–µ—Å—Ç–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
{
  "rating": number, // 1-5
  "comment": "string",
  "helpful": boolean
}
```

### GraphQL API –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

```graphql
# –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∞–¥–º–∏–Ω–∫–∏
type Query {
  # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
  testStats(testId: String!, dateRange: DateRange!): TestStatistics
  
  # –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
  demographicBreakdown(
    testId: String!
    groupBy: [DemographicField!]!
    dateRange: DateRange!
  ): [DemographicGroup!]!
  
  # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
  correlationAnalysis(
    testId: String!
    factors: [AnalysisFactor!]!
    dateRange: DateRange!
  ): CorrelationResult
  
  # –¢—Ä–µ–Ω–¥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
  trendAnalysis(
    testId: String!
    metric: TrendMetric!
    interval: TimeInterval!
    dateRange: DateRange!
  ): [TrendPoint!]!
}

type TestStatistics {
  totalCompletions: Int!
  completionRate: Float!
  avgScore: Float!
  avgDuration: Int! # seconds
  levelDistribution: LevelDistribution!
}

type DemographicGroup {
  groupKey: String!
  sampleSize: Int!
  avgScore: Float!
  stdDeviation: Float!
  completionRate: Float!
}
```

## üìä –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞  

### 1. Real-time –¥–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫–∏

```sql
-- –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
CREATE MATERIALIZED VIEW mv_test_stats_realtime AS
SELECT 
    test_id,
    DATE(completed_at) as completion_date,
    COUNT(*) as total_completions,
    AVG(final_score) as avg_score,
    AVG(duration_seconds) as avg_duration,
    
    -- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º
    COUNT(*) FILTER (WHERE level = 'minimal') as minimal_count,
    COUNT(*) FILTER (WHERE level = 'mild') as mild_count,
    COUNT(*) FILTER (WHERE level = 'moderate') as moderate_count,
    COUNT(*) FILTER (WHERE level = 'high') as high_count,
    COUNT(*) FILTER (WHERE level = 'critical') as critical_count,
    
    -- –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–±–∏–≤–∫–∞
    AVG(final_score) FILTER (WHERE u.gender = 'male') as male_avg_score,
    AVG(final_score) FILTER (WHERE u.gender = 'female') as female_avg_score,
    
    MAX(completed_at) as last_updated
FROM test_results tr
JOIN users u ON tr.user_id = u.id
WHERE completed_at >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY test_id, DATE(completed_at);

-- –ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç
SELECT cron.schedule('refresh-stats', '*/15 * * * *', 'REFRESH MATERIALIZED VIEW CONCURRENTLY mv_test_stats_realtime;');
```

### 2. –°–∏—Å—Ç–µ–º–∞ –∞–ª–µ—Ä—Ç–æ–≤

```sql
-- –ê–ª–µ—Ä—Ç—ã –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö
CREATE OR REPLACE FUNCTION check_completion_rate_drop() RETURNS void AS $$
BEGIN
    -- –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑–∫–æ–µ –ø–∞–¥–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    IF (
        SELECT completion_rate 
        FROM daily_stats 
        WHERE date = CURRENT_DATE - 1
    ) < (
        SELECT AVG(completion_rate) * 0.8  -- –º–µ–Ω—å—à–µ 80% –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
        FROM daily_stats 
        WHERE date >= CURRENT_DATE - 30
    ) THEN
        -- –û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º
        INSERT INTO system_alerts (type, message, severity, created_at) 
        VALUES (
            'completion_rate_drop', 
            'Completion rate dropped significantly yesterday',
            'high',
            NOW()
        );
    END IF;
END;
$$ LANGUAGE plpgsql;
```

### 3. ETL –ø—Ä–æ—Ü–µ—Å—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

```python
# Python —Å–∫—Ä–∏–ø—Ç –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
import pandas as pd
import numpy as np
from sqlalchemy import create_engine

def daily_analytics_etl():
    """–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    
    engine = create_engine(DATABASE_URL)
    
    # 1. –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –µ–∂–µ–¥–Ω–µ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    daily_agg_query = """
    INSERT INTO daily_stats (date, test_id, total_completions, completion_rate, ...)
    SELECT 
        DATE(completed_at) as date,
        test_id,
        COUNT(*) as total_completions,
        -- —Ä–∞—Å—á–µ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫...
    FROM test_results 
    WHERE DATE(completed_at) = CURRENT_DATE - 1
    GROUP BY DATE(completed_at), test_id
    ON CONFLICT (date, test_id) DO UPDATE SET
        total_completions = EXCLUDED.total_completions,
        -- –æ–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ –ø–æ–ª—è...
    """
    
    # 2. –û–±–Ω–æ–≤–ª—è–µ–º –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    demographic_agg_query = """
    INSERT INTO demographic_stats (period_start, period_end, test_id, age_group, gender, ...)
    SELECT 
        CURRENT_DATE - 7 as period_start,
        CURRENT_DATE - 1 as period_end,
        test_id,
        CASE 
            WHEN age <= 25 THEN '18-25'
            WHEN age <= 35 THEN '26-35'
            -- –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ...
        END as age_group,
        gender,
        COUNT(*) as sample_size,
        AVG(final_score) as avg_score,
        STDDEV(final_score) as std_deviation
    FROM test_results tr
    JOIN users u ON tr.user_id = u.id
    WHERE completed_at >= CURRENT_DATE - 7 
      AND completed_at < CURRENT_DATE
    GROUP BY test_id, age_group, gender
    """
    
    # 3. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    df = pd.read_sql("""
        SELECT tr.final_score, u.age, u.gender, tr.duration_seconds
        FROM test_results tr
        JOIN users u ON tr.user_id = u.id  
        WHERE completed_at >= CURRENT_DATE - 30
    """, engine)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    correlations = df.corr()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    save_correlations_to_db(correlations, engine)

def save_correlations_to_db(corr_matrix, engine):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –≤ –±–∞–∑—É"""
    # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è...
    pass

# –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ cron –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –≤ 2:00
# 0 2 * * * /usr/local/bin/python /path/to/daily_analytics_etl.py
```

## üìà –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### 1. –ü—Å–∏—Ö–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

```sql
-- –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–∞ (–ê–ª—å—Ñ–∞ –ö—Ä–æ–Ω–±–∞—Ö–∞)
WITH question_correlations AS (
    SELECT 
        qa1.question_id as q1,
        qa2.question_id as q2,
        CORR(qa1.answer_score, qa2.answer_score) as correlation
    FROM question_answers qa1
    JOIN question_answers qa2 ON qa1.result_id = qa2.result_id
    WHERE qa1.question_id != qa2.question_id
    GROUP BY qa1.question_id, qa2.question_id
)
SELECT 
    AVG(correlation) as avg_inter_item_correlation,
    -- –†–∞—Å—á–µ—Ç –∞–ª—å—Ñ–∞ –ö—Ä–æ–Ω–±–∞—Ö–∞
    (COUNT(DISTINCT q1) * AVG(correlation)) / 
    (1 + (COUNT(DISTINCT q1) - 1) * AVG(correlation)) as cronbach_alpha
FROM question_correlations;
```

### 2. –ü—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞

```python
# ML –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

def build_predictive_model():
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –±–∞–ª–ª–∞"""
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    query = """
    SELECT 
        u.age,
        u.gender,
        u.occupation,
        tr.duration_seconds,
        COUNT(qa.id) as questions_answered,
        AVG(qa.time_to_answer_seconds) as avg_response_time,
        tr.final_score
    FROM test_results tr
    JOIN users u ON tr.user_id = u.id
    JOIN question_answers qa ON tr.id = qa.result_id
    GROUP BY u.id, tr.id
    """
    
    df = pd.read_sql(query, engine)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    df_encoded = pd.get_dummies(df, columns=['gender', 'occupation'])
    
    X = df_encoded.drop(['final_score'], axis=1)
    y = df_encoded['final_score']
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    score = model.score(X_test, y_test)
    print(f"Model R¬≤ score: {score:.3f}")
    
    return model

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ API
def save_model_for_api(model):
    import joblib
    joblib.dump(model, '/models/stress_predictor.pkl')
```

### 3. A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```sql
-- –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è A/B —Ç–µ—Å—Ç–æ–≤
CREATE TABLE ab_tests (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL,
    test_id VARCHAR(50) REFERENCES tests(id),
    
    -- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    variant_a_config JSONB NOT NULL,
    variant_b_config JSONB NOT NULL,
    
    -- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–µ—Å—Ç–∞
    traffic_split DECIMAL(3,2) DEFAULT 0.5, -- 50/50 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    start_date DATE NOT NULL,
    end_date DATE,
    
    -- –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
    primary_metric VARCHAR(100), -- 'completion_rate', 'avg_score', etc
    
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∫ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º
CREATE TABLE ab_test_assignments (
    user_id UUID REFERENCES users(id),
    test_id UUID REFERENCES ab_tests(id),
    variant CHAR(1) CHECK (variant IN ('A', 'B')),
    assigned_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    PRIMARY KEY (user_id, test_id)
);

-- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã A/B —Ç–µ—Å—Ç–∞
CREATE VIEW ab_test_results AS
SELECT 
    at.id as test_id,
    at.name as test_name,
    ata.variant,
    COUNT(DISTINCT tr.user_id) as participants,
    COUNT(tr.id) as completions,
    AVG(tr.final_score) as avg_score,
    AVG(tr.duration_seconds) as avg_duration,
    COUNT(tr.id)::DECIMAL / COUNT(DISTINCT tr.user_id) as completion_rate
FROM ab_tests at
JOIN ab_test_assignments ata ON at.id = ata.test_id  
LEFT JOIN test_results tr ON ata.user_id = tr.user_id
WHERE at.is_active = true
GROUP BY at.id, at.name, ata.variant;
```

## üîê –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å

### 1. –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

```sql
-- –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
CREATE EXTENSION IF NOT EXISTS pgcrypto;

-- –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ PII –¥–∞–Ω–Ω—ã—Ö
ALTER TABLE users ADD COLUMN email_encrypted BYTEA;
ALTER TABLE users ADD COLUMN name_encrypted BYTEA;

-- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è/–¥–µ—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
CREATE OR REPLACE FUNCTION encrypt_pii(data TEXT) RETURNS BYTEA AS $$
BEGIN
    RETURN pgp_sym_encrypt(data, current_setting('app.encryption_key'));
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

CREATE OR REPLACE FUNCTION decrypt_pii(encrypted_data BYTEA) RETURNS TEXT AS $$
BEGIN
    RETURN pgp_sym_decrypt(encrypted_data, current_setting('app.encryption_key'));
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

### 2. –ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π

```sql
-- –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–æ–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
CREATE VIEW anonymous_results AS
SELECT 
    md5(user_id::TEXT) as anonymous_user_id,
    test_id,
    final_score,
    level,
    CASE 
        WHEN age BETWEEN 18 AND 25 THEN '18-25'
        WHEN age BETWEEN 26 AND 35 THEN '26-35' 
        -- –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ...
    END as age_group,
    gender,
    CASE 
        WHEN occupation ILIKE '%–≤—Ä–∞—á%' THEN 'healthcare'
        WHEN occupation ILIKE '%—É—á–∏—Ç–µ–ª—å%' THEN 'education'
        -- –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–π...
        ELSE 'other'
    END as occupation_category,
    completed_at
FROM test_results tr
JOIN users u ON tr.user_id = u.id
WHERE completed_at >= CURRENT_DATE - INTERVAL '1 year';
```

### 3. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ GDPR

```sql  
-- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º
CREATE TABLE data_access_log (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID,
    accessed_by VARCHAR(255), -- email –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    access_type VARCHAR(50), -- 'view', 'export', 'analyze'
    data_scope TEXT, -- –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã
    purpose TEXT, -- —Ü–µ–ª—å –¥–æ—Å—Ç—É–ø–∞
    accessed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
CREATE OR REPLACE FUNCTION gdpr_delete_user_data(target_user_id UUID) RETURNS void AS $$
BEGIN
    -- –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    DELETE FROM question_answers WHERE result_id IN 
        (SELECT id FROM test_results WHERE user_id = target_user_id);
    DELETE FROM test_results WHERE user_id = target_user_id;
    DELETE FROM test_sessions WHERE user_id = target_user_id;
    DELETE FROM data_access_log WHERE user_id = target_user_id;
    DELETE FROM users WHERE id = target_user_id;
    
    -- –õ–æ–≥–∏—Ä—É–µ–º —É–¥–∞–ª–µ–Ω–∏–µ
    INSERT INTO deletion_log (user_id, deleted_at, deleted_by) 
    VALUES (target_user_id, NOW(), current_user);
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

## üöÄ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

### 1. Docker-compose –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

```yaml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: psy_tests
      POSTGRES_USER: psy_tests_user
      POSTGRES_PASSWORD: your_secure_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    
  api:
    build: .
    ports:
      - "3000:3000"
    environment:
      DATABASE_URL: postgres://psy_tests_user:your_secure_password@postgres:5432/psy_tests
      REDIS_URL: redis://redis:6379
    depends_on:
      - postgres
      - redis

volumes:
  postgres_data:
```

### 2. –°—Ç—Ä–∞—Ç–µ–≥–∏—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è

```sql
-- –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü –ø–æ –¥–∞—Ç–µ
CREATE TABLE test_results_2025 PARTITION OF test_results
FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');

CREATE TABLE test_results_2026 PARTITION OF test_results  
FOR VALUES FROM ('2026-01-01') TO ('2027-01-01');

-- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
CREATE INDEX idx_test_results_2025_completed_at ON test_results_2025 (completed_at);
CREATE INDEX idx_test_results_2026_completed_at ON test_results_2026 (completed_at);
```

### 3. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```sql
-- –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
CREATE VIEW slow_queries AS
SELECT 
    query,
    calls,
    total_exec_time,
    mean_exec_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) as hit_percent
FROM pg_stat_statements
WHERE mean_exec_time > 100 -- –∑–∞–ø—Ä–æ—Å—ã –¥–æ–ª—å—à–µ 100–º—Å
ORDER BY total_exec_time DESC;
```

## üìã –ü–ª–∞–Ω –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### –§–∞–∑–∞ 1: –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (1-2 –Ω–µ–¥–µ–ª–∏)
1. ‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ PostgreSQL —Å –±–∞–∑–æ–≤–æ–π —Å—Ö–µ–º–æ–π
2. ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ API endpoints –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Ç–µ—Å—Ç–æ–≤
3. ‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ localStorage
4. ‚úÖ –ë–∞–∑–æ–≤–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (–µ–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)

### –§–∞–∑–∞ 2: –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (2-3 –Ω–µ–¥–µ–ª–∏)
1. ‚úÖ –ú–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
2. ‚úÖ GraphQL API –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤  
3. ‚úÖ –î–∞—à–±–æ—Ä–¥ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
4. ‚úÖ –°–∏—Å—Ç–µ–º–∞ –∞–ª–µ—Ä—Ç–æ–≤ –Ω–∞ –∞–Ω–æ–º–∞–ª–∏–∏

### –§–∞–∑–∞ 3: ML –∏ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (3-4 –Ω–µ–¥–µ–ª–∏)
1. ‚úÖ Python ETL –ø—Ä–æ—Ü–µ—Å—Å—ã
2. ‚úÖ ML –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
3. ‚úÖ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞
4. ‚úÖ –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –§–∞–∑–∞ 4: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ (–ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
1. ‚úÖ Real-time –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å –ø–æ–º–æ—â—å—é Apache Kafka
2. ‚úÖ Data Lake –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
3. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏ (CRM, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∫–∞—Ä—Ç—ã)
4. ‚úÖ –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –ø—Å–∏—Ö–æ–ª–æ–≥–æ–≤

---

**üí° –≠—Ç–æ—Ç –ø–ª–∞–Ω –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:**
- –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∏–ª–ª–∏–æ–Ω–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–æ–≤
- –ë—ã—Å—Ç—Ä—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É —Å –ø–æ–º–æ—â—å—é –∏–Ω–¥–µ–∫—Å–æ–≤ –∏ –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π  
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏ (GDPR)
- –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é –∏ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–µ
- –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ —É–ª—É—á—à–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤